# Этот файл реализует мониторинг логов приложений 
# используя кластер Elasticsearch 


version: '3'
services:
  # генерирует тестовый лог для проверки работоспособности системы
  # Проект https://git.rgwork.ru/ivlev/log-generator
  #
  # **log-generator** образует ротируемый лог logrus.log на диске , записи которого отсылаются
  # filebeat-ом в elk в сохраняются в индексе filebeat-*.
  # Настройки filebeat смотри в файле `configs/filebeat.yml`.
  # log-generator также отправляет новые записи лога напрямую в Эластик в
  # индекс logrus-*. См. код log-generator.
  log-generator:
    image: vadimivlev/log-generator:0.0.1
    container_name: log-generator
    restart: unless-stopped
    environment:
      # максимальная задержка добавления записей в лог
      - MAX_DELAY=5000
      # максимальное количество добавленных записей лога перед ротацией
      - MAX_RECORDS=10
      # имя файла лога внутри директории назначенной в параметре volumes:
      - LOG_FILE=logrus.log
      # адрес elasticsearch для прямой записи логов
      - ELASTIC_URL=http://es01:9200
      # хост elasticsearch для прямой записи логов
      - ELASTIC_HOST=es01
    volumes:
      - ./logs:/app/logs

  # следит за новыми файлами логов и посылает информацию о новых записях
  # согласно настройкам определенным в filebeat.yml
  log-monitor-filebeat:
    image: docker.elastic.co/beats/filebeat:7.7.0
    container_name: log-monitor-filebeat
    restart: unless-stopped
    volumes:
      # настроечный файл Filebeat
      - ./configs/filebeat.yml:/usr/share/filebeat/filebeat.yml
      # директория где Filebeat следит за файлами логов
      - ./logs:/logs
      # сертификат для связи с Logstash по SSL
      # - ./configs/logstash-beats.crt:/etc/pki/tls/certs/logstash-beats.crt
    # чтобы не сыпало ошибки на экран для output.console определенного в ./configs/filebeat.yml убрать -e
    #  и ослабить ограничения по доступу --strict.perms=false
    # https://www.elastic.co/guide/en/beats/libbeat/7.6/config-file-permissions.html
    command: filebeat -e --strict.perms=false

  # Кластер elasticsearch
  # E L A S T I C S E A R C H   C L U S T E R  B E G I N -----------------------------------------------------------
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es01
    restart: unless-stopped
    environment:
      - node.name=es01
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      # - cluster.initial_master_nodes=es01
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # добавить это к каждой службе эластик если свободного места на диске < 10%
      # в противном случае шарды не будут двигаться
      # - cluster.routing.allocation.disk.threshold_enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    # ports:
    #   - 9200:9200
    volumes:
      - data01:/usr/share/elasticsearch/data

  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es02
    restart: unless-stopped
    environment:
      - node.name=es02
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
  
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es03
    restart: unless-stopped
    environment:
      - node.name=es03
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
  # E L A S T I C S E A R C H   C L U S T E R  E N D -----------------------------------------------------------
  
  
  
  # Kibana. Визуализация данных elasticsearch
  kibana01:
    image: docker.elastic.co/kibana/kibana:7.7.0
    container_name: kibana01
    restart: unless-stopped
    # ports:
    #   - 5601:5601
    environment:
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
  
  # Cerebro. Визуализация кластера elasticsearch
  cerebro01:
    image: lmenezes/cerebro
    container_name: cerebro01
    restart: unless-stopped
    # left to try through auth-proxy
    # ports:
    #   - 9000:9000
    environment:
      CEREBRO_PORT: 9000
    

  # Caddy HTTP сервер, добавлен для базовой аутентификации к Кибане
  # и ограничения доступа к elasticsearch со стороны внешних программ.
  # Параметры проксирования определены в Caddyfile
  log-monitor-caddy:
    image: caddy:2.0.0-alpine
    container_name: log-monitor-caddy
    restart: unless-stopped
    ports:
      - '9094:8080'
      - '9095:8081'
    volumes:
      - ./configs/Caddyfile:/etc/caddy/Caddyfile
      - ./www:/www


  # Portainer. Управление докер контейнерами хоста
  log-monitor-portainer:
    image: portainer/portainer:1.24.0
    container_name: log-monitor-portainer
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
  
  # Jupiter notebooks
  # log-monitor-notebook:
  #   build: 
  #       context: .
  #       dockerfile: Dockerfile-anaconda3
  #   image: log-monitor-notebook
  #   container_name: log-monitor-notebook
  #   restart: unless-stopped
  #   volumes: 
  #       - ./notebooks:/opt/notebooks

  log-monitor-notebook:
    # build: 
    #     context: .
    #     dockerfile: Dockerfile-datascience 
    image: vadimivlev/datascience-notebook-plus:latest
    # image: jupyter/datascience-notebook:latest
    container_name: log-monitor-notebook
    restart: unless-stopped
    # command: /opt/conda/bin/jupyter notebook  --ip="*" --port=8888 --notebook-dir=/home/jovyan/work --no-browser --allow-root  --NotebookApp.token="abc"
    volumes: 
        - notebook_data:/home/jovyan/work
  

# volumes for Elasticsearch data and Portainer
volumes:
  data01:
  data02:
  data03:
  portainer_data:
  notebook_data:

# outer network to communicate with other services 
networks:
    default:
      external:
        name: auth_proxy_network
